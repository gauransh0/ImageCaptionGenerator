{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install rouge_score -q\n!pip install deep-phonemizer -q\nclear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-27T15:00:09.913828Z","iopub.execute_input":"2022-12-27T15:00:09.914632Z","iopub.status.idle":"2022-12-27T15:00:33.94049Z","shell.execute_reply.started":"2022-12-27T15:00:09.914537Z","shell.execute_reply":"2022-12-27T15:00:33.939212Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport datasets\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport multiprocessing as mp\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import io, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom transformers import Seq2SeqTrainer ,Seq2SeqTrainingArguments\nfrom transformers import VisionEncoderDecoderModel , ViTFeatureExtractor\nfrom transformers import AutoTokenizer ,  GPT2Config , default_data_collator\n\n\nif torch.cuda.is_available():    \n\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:01:41.534903Z","iopub.execute_input":"2022-12-27T15:01:41.535276Z","iopub.status.idle":"2022-12-27T15:01:41.544056Z","shell.execute_reply.started":"2022-12-27T15:01:41.535244Z","shell.execute_reply":"2022-12-27T15:01:41.542985Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\nclass config : \n    ENCODER = \"google/vit-base-patch16-224\"\n    DECODER = \"gpt2\"\n    TRAIN_BATCH_SIZE = 8\n    VAL_BATCH_SIZE = 8\n    VAL_EPOCHS = 1\n    LR = 5e-5\n    SEED = 42\n    MAX_LEN = 128\n    SUMMARY_LEN = 20\n    WEIGHT_DECAY = 0.01\n    MEAN = (0.485, 0.456, 0.406)\n    STD = (0.229, 0.224, 0.225)\n    TRAIN_PCT = 0.95\n    NUM_WORKERS = mp.cpu_count()\n    EPOCHS = 3\n    IMG_SIZE = (224,224)\n    LABEL_MASK = -100\n    TOP_K = 1000\n    TOP_P = 0.95","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:01:42.820109Z","iopub.execute_input":"2022-12-27T15:01:42.820919Z","iopub.status.idle":"2022-12-27T15:01:42.82854Z","shell.execute_reply.started":"2022-12-27T15:01:42.820869Z","shell.execute_reply":"2022-12-27T15:01:42.827272Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n    return outputs\nAutoTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:01:43.105529Z","iopub.execute_input":"2022-12-27T15:01:43.107438Z","iopub.status.idle":"2022-12-27T15:01:43.113518Z","shell.execute_reply.started":"2022-12-27T15:01:43.107399Z","shell.execute_reply":"2022-12-27T15:01:43.11246Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge = datasets.load_metric(\"rouge\")\n\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    # all unnecessary tokens are removed\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor = ViTFeatureExtractor.from_pretrained(config.ENCODER)\ntokenizer = AutoTokenizer.from_pretrained(config.DECODER)\ntokenizer.pad_token = tokenizer.unk_token","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:01:43.497783Z","iopub.execute_input":"2022-12-27T15:01:43.498151Z","iopub.status.idle":"2022-12-27T15:01:48.63891Z","shell.execute_reply.started":"2022-12-27T15:01:43.49812Z","shell.execute_reply":"2022-12-27T15:01:48.637899Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = transforms.Compose(\n    [\n        transforms.Resize(config.IMG_SIZE), \n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=0.5, \n            std=0.5\n        )\n   ]\n)\ndf=  pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\")\ntrain_df , val_df = train_test_split(df , test_size = 0.2)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:01:48.642794Z","iopub.execute_input":"2022-12-27T15:01:48.643099Z","iopub.status.idle":"2022-12-27T15:01:48.650869Z","shell.execute_reply.started":"2022-12-27T15:01:48.643071Z","shell.execute_reply":"2022-12-27T15:01:48.649821Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImgDataset(Dataset):\n    def __init__(self, df,root_dir,tokenizer,feature_extractor, transform = None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n        self.tokenizer= tokenizer\n        self.feature_extractor = feature_extractor\n        self.max_length = 50\n    def __len__(self,):\n        return len(self.df)\n    def __getitem__(self,idx):\n        caption = self.df.caption.iloc[idx]\n        image = self.df.image.iloc[idx]\n        img_path = os.path.join(self.root_dir , image)\n        img = Image.open(img_path).convert(\"RGB\")\n        \n        if self.transform is not None:\n            img= self.transform(img)\n        pixel_values = self.feature_extractor(img, return_tensors=\"pt\").pixel_values\n        captions = self.tokenizer(caption,\n                                 padding='max_length',\n                                 max_length=self.max_length).input_ids\n        captions = [caption if caption != self.tokenizer.pad_token_id else -100 for caption in captions]\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(captions)}\n        return encoding\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:03:04.380763Z","iopub.execute_input":"2022-12-27T15:03:04.381125Z","iopub.status.idle":"2022-12-27T15:03:04.390323Z","shell.execute_reply.started":"2022-12-27T15:03:04.38109Z","shell.execute_reply":"2022-12-27T15:03:04.38924Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImgDataset(train_df, root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor ,transform = transforms)\nval_dataset = ImgDataset(val_df , root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor , transform  = transforms)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:03:04.500044Z","iopub.execute_input":"2022-12-27T15:03:04.500622Z","iopub.status.idle":"2022-12-27T15:03:04.505797Z","shell.execute_reply.started":"2022-12-27T15:03:04.500583Z","shell.execute_reply":"2022-12-27T15:03:04.504655Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(config.ENCODER, config.DECODER)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:01:52.754916Z","iopub.execute_input":"2022-12-27T15:01:52.755746Z","iopub.status.idle":"2022-12-27T15:03:04.378701Z","shell.execute_reply.started":"2022-12-27T15:01:52.7557Z","shell.execute_reply":"2022-12-27T15:03:04.377724Z"},"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n# make sure vocab size is set correctly\nmodel.config.vocab_size = model.config.decoder.vocab_size\n# set beam search parameters\nmodel.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.decoder_start_token_id = tokenizer.bos_token_id\nmodel.config.max_length = 128\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='VIT_large_gpt2',\n    per_device_train_batch_size=config.TRAIN_BATCH_SIZE,\n    per_device_eval_batch_size=config.VAL_BATCH_SIZE,\n    predict_with_generate=True,\n    evaluation_strategy=\"epoch\",\n    do_train=True,\n    do_eval=True,\n    logging_steps=1024,  \n    save_steps=2048, \n    warmup_steps=1024,  \n    learning_rate = 5e-5,\n    #max_steps=1500, # delete for full training\n    num_train_epochs = config.EPOCHS, #TRAIN_EPOCHS\n    overwrite_output_dir=True,\n    save_total_limit=1,\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:03:05.860831Z","iopub.execute_input":"2022-12-27T15:03:05.861305Z","iopub.status.idle":"2022-12-27T15:03:05.872477Z","shell.execute_reply.started":"2022-12-27T15:03:05.861267Z","shell.execute_reply":"2022-12-27T15:03:05.871514Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    tokenizer=feature_extractor,\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T15:03:05.873981Z","iopub.execute_input":"2022-12-27T15:03:05.874387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('VIT_large_gpt2')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}